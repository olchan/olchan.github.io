{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Import Library**"],"metadata":{"id":"ORmjcHlT-Qgm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ReeHrtxm-LYC"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","import time\n","import random\n","import copy"]},{"cell_type":"markdown","source":["# **Define Model**"],"metadata":{"id":"ajdGNW55-WUN"}},{"cell_type":"code","source":["\"\"\"# **1) Model define**\n","### trans_VGG에서 사용할 함수인 conv_2 define\n","\"\"\"\n","\n","def conv_2(in_dim, out_dim):\n","    model = nn.Sequential(\n","        nn.Conv2d(in_dim, out_dim, kernel_size = 3, padding = 1),\n","        nn.ReLU(),# Model define\n","        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2,2)\n","    )\n","    return model\n","\n","def conv_3(in_dim, out_dim):\n","    model = nn.Sequential(\n","        nn.Conv2d(in_dim, out_dim, kernel_size = 3, padding = 1),\n","        nn.ReLU(),# Model define\n","        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n","        nn.ReLU(),\n","        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n","        nn.ReLU(),\n","        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2,2)\n","    )\n","    return model"],"metadata":{"id":"YnrVUVGl-ZGr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 코드의 구조\n","# conv_2는 두 개의 합성곱-활성화 조합과 하나의 맥스풀링 층으로 구성되어 있다.\n","# conv_3는 네 개의 합성곱-활성화 조합과 하나의 맥스풀링 층으로 구성되어 있다."],"metadata":{"id":"B86BBuacl5ht"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Define trans_VGG class**"],"metadata":{"id":"DtjKQ3Ss-eOM"}},{"cell_type":"code","source":["class trans_VGG(nn.Module):\n","    def __init__(self, base_dim):\n","        super(trans_VGG, self).__init__()\n","        self.feature = nn.Sequential(\n","            conv_2(3, base_dim),\n","            conv_2(base_dim, base_dim*2),\n","            conv_2(base_dim*2, base_dim*4),\n","            conv_3(base_dim*4, base_dim*8),\n","            conv_3(base_dim*8, base_dim*8)\n","        )\n","        self.fc_layer = nn.Sequential(\n","            nn.Linear(base_dim*8*7*7, base_dim*4*7*7),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(base_dim*4*7*7, base_dim*2*7*7),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(base_dim*2*7*7, base_dim*7*7)\n","        )\n","        for param in self.parameters():\n","            param.requires_grad = True\n","\n","    def forward(self, x):\n","        x = self.feature(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc_layer(x)\n","        return x"],"metadata":{"id":"3Ty-Lx7--jv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 코드의 구조\n","\n","# 초기화 메서드 (__init__)\n","# base_dim: 네트워크의 기본 채널 수를 결정하는 파라미터\n","\n","# 특징 추출 부분 (self.feature)\n","# 이전에 정의한 합성곱 블록 함수로, 각각 2개와 4개의 합성곱 층과 활성화 함수를 포함한 convolution layer\n","\n","\"\"\"\n","- 첫 번째 블록 (conv_2(3, base_dim)):\n","입력 채널: 3 (RGB 이미지)\n","출력 채널: base_dim\n","\n","- 두 번째 블록 (conv_2(base_dim, base_dim*2)):\n","입력 채널: base_dim\n","출력 채널: base_dim*2\n","\n","- 세 번째 블록 (conv_2(base_dim*2, base_dim*4)):\n","입력 채널: base_dim*2\n","출력 채널: base_dim*4\n","\n","- 네 번째 블록 (conv_3(base_dim*4, base_dim*8)):\n","입력 채널: base_dim*4\n","출력 채널: base_dim*8\n","\n","- 다섯 번째 블록 (conv_3(base_dim*8, base_dim*8)):\n","입력 및 출력 채널: base_dim*8\n","\"\"\"\n","\n","# 완전 연결 층 (self.fc_layer)\n","\"\"\"\n","nn.Linear: 선형 변환(완전 연결 층)을 수행합니다.\n","\n","- 활성화 함수 및 드롭아웃\n","nn.ReLU(True): 활성화 함수로 ReLU를 사용하며, 인플레이스 연산을 수행합니다.\n","nn.Dropout(): 과적합을 방지하기 위해 드롭아웃을 적용합니다.\n","\"\"\"\n","\n","# 파라미터 학습 설정\n","# 모든 파라미터의 requires_grad 속성을 True로 설정하여 역전파 시 파라미터가 업데이트되도록 합니다.\n","\n","# 순전파 메서드 (forward)\n","# x = self.feature(x): 입력 데이터를 특징 추출 부분에 통과시켜 특징 맵을 얻습니다.\n","# x = x.view(x.size(0), -1): 다차원 텐서를 2차원 텐서로 변환하여 완전 연결 층에 입력할 수 있도록 합니다.\n","# x = self.fc_layer(x): 완전 연결 층을 통과하여 최종 출력을 생성합니다.\n","\n","\"\"\"\n","< 모델의 전체적인 흐름>\n","입력 단계: 배치 크기의 RGB 이미지를 입력으로 받습니다.\n","특징 추출 단계 (self.feature): 합성곱 및 풀링 층을 통해 이미지의 공간적 및 계층적 특징을 추출합니다. 각 블록에서 채널 수가 증가하여 더 복잡한 특징을 학습할 수 있습니다.\n","평탄화 단계: 합성곱 층의 출력을 펼쳐서 완전 연결 층의 입력으로 사용합니다.\n","분류 또는 회귀 단계 (self.fc_layer): 완전 연결 층을 통해 최종 출력을 계산합니다.활성화 함수와 드롭아웃을 사용하여 모델의 일반화 성능을 향상시킵니다.\n","\"\"\""],"metadata":{"id":"n73iWbZImUv1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Hyper_paremeter : Learning rate, momentum, weight decay 등은 논문의 Hyper peremeter value로 초기화\n"],"metadata":{"id":"0JlwvIx9-oB3"}},{"cell_type":"code","source":["import torch.nn.init as init\n","\n","seed = time.time()\n","\n","def custom_init_weights(m):\n","  if seed is not None:\n","    torch.manual_seed(seed)\n","  if isinstance(m, torch.nn.Linear) and m.weight is not None:\n","    init.normal_(m.weight, mean=1, std=0.01)\n","    if m.bias is not None:\n","      init.constant_(m.bias, 0)\n","\n","model = trans_VGG(base_dim=64)\n","\n","loss = nn.BCELoss()\n","optimizer =torch.optim.SGD(model.parameters(), lr = 0.01,momentum = 0.9, weight_decay = 0.0005)\n","scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=10, factor=0.1, verbose=True)\n","\n","transform = transforms.Compose(\n","    [transforms.ToTensor(), transforms.RandomCrop(224)])\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"_79OsMOG-olp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 코드의 구조\n","\n","# custom_init_weights 함수 : 모델 내의 nn.Linear 계층의 가중치와 바이어스를 특정 방식으로 초기화\n","# 가중치 초기화: init.normal_(m.weight, mean=1, std=0.01): 가중치를 평균이 1이고 표준편차가 0.01인 정규분포로 초기화\n","# 바이어스 초기화: init.constant_(m.bias, 0): 바이어스를 0으로 초기화\n","\n","# 모델 인스턴스화\n","# trans_VGG 클래스: 이전에 정의한 VGG 네트워크 기반의 커스텀 신경망 모델\n","\n","# 손실함수 정의\n","# nn.BCELoss(): 이진 분류를 위한 바이너리 크로스 엔트로피 손실 함수입니다.\n","# 이 손실 함수를 사용할 때는 모델의 출력이 시그모이드 함수를 통과하여 0과 1 사이의 값이 되어야한다.\n","\n","# 옵티마이저 설정 : torch.optim.SGD: 확률적 경사 하강법(SGD) 옵티마이저를 사용합니다\n","# lr=0.01: 학습률을 0.01로 설정합니다.\n","# momentum=0.9: 모멘텀을 사용하여 학습 속도를 가속화하고 진동을 줄입니다.\n","# weight_decay=0.0005: 가중치 감쇠(L2 정규화)를 적용하여 과적합을 방지합니다.\n","\n","# 학습률 스케줄러 설정\n","# 모델의 성능 향상이 멈췄을 때 학습률을 줄여주는 스케줄러"],"metadata":{"id":"ACmx8N5SmZlC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Import Dataset**"],"metadata":{"id":"iDUjpjGy-wJn"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","# Project 3 폴더 경로\n","project_folder = '/content/drive/MyDrive/Project3'\n","\n","image = []\n","label = []\n","\n","# Project 3 폴더 내부의 세부 폴더를 확인하고 이미지와 라벨 데이터 생성\n","for subdir, _, files in os.walk(project_folder):\n","    for file in files:\n","        # 이미지 파일인지 확인\n","        if file.endswith(('png', 'jpg', 'jpeg')):\n","            image_path = os.path.join(subdir, file)\n","            image.append(image_path)\n","\n","            # 이미지가 속한 세부 폴더의 이름을 라벨로 사용\n","            label_name = os.path.basename(subdir)\n","            label.append(label_name)\n","\n","indices = np.random.permutation(len(image))\n","IMAGE = [image[i] for i in indices]\n","LABEL = [label[i] for i in indices]\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, image_paths, labels, transform=None):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        label = self.labels[idx]\n","        image = Image.open(image_path).convert('RGB')\n","        image = transforms.RandomCrop(224)(image)\n","        image = transforms.ToTensor()(image)\n","\n","        return image, label\n","\n","BATCH_SIZE = 1\n","\n","TRAINING_image = []\n","TRAINING_label = []\n","TEST_image = []\n","TEST_label = []\n","\n","for i in range(0,80):\n","  for j in range(0,20):\n","    for k in range(0,2):\n","      TRAINING_image.append(image[200*j+i+k])\n","      TRAINING_label.append(label[200*j+i+k])\n","\n","for i in range(80,100):\n","  for j in range(0,20):\n","    for k in range(0,2):\n","      TEST_image.append(image[200*j+i+k])\n","      TEST_label.append(label[200*j+i+k])\n","\n","train_dataset = CustomDataset(TRAINING_image, TRAINING_label, transform = transform)\n","train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE,num_workers=2)\n","test_dataset = CustomDataset(TEST_image, TEST_label, transform = transform)\n","test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE,num_workers=2)"],"metadata":{"id":"l7NWSJZD-yoP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 코드의 구조\n","\n","# 데이터 수집 및 전처리: 지정된 디렉토리에서 이미지 파일과 해당 라벨을 수집합니다. 데이터를 무작위로 섞어 순서에 의한 영향을 최소화합니다.\n","# 데이터셋 분할:수집된 데이터를 훈련용과 테스트용으로 분할합니다. 분할 로직은 인덱스 계산을 통해 특정 이미지를 선택하는 방식입니다.\n","# 데이터셋 및 데이터로더 생성: 커스텀 데이터셋 클래스를 정의하고, 이를 통해 데이터셋 객체를 만듭니다. 데이터로더를 사용하여 배치 단위로 데이터를 모델에 공급할 수 있도록 준비합니다."],"metadata":{"id":"5-enzp3bqDkh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Training**"],"metadata":{"id":"61PMWGKo-2dQ"}},{"cell_type":"code","source":["\"\"\"# **3) TRAINING**\"\"\"\n","\n","EPOCH = 80\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(DEVICE)\n","\n","start_time = time.time()\n","train_acc_lst, test_acc_lst = [],[]\n","\n","for epoch in range(EPOCH):\n","  model.train()\n","  correct_pred, num_examples = 0, 3200\n","  for i, (_image1, _label1) in enumerate(train_loader):\n","    image1 = _image1.to(DEVICE)\n","    label1 = _label1[0]\n","    vector1_tensor = model(image1)\n","\n","    if (i == 0): #Exception Case\n","      image2 = image1\n","      label2 = label1\n","      vector2_tensor = vector1_tensor\n","\n","    similarity =  F.cosine_similarity(vector1_tensor, vector2_tensor, dim= -1)\n","    scaled_similarity = torch.sigmoid(similarity)\n","\n","    if label1 == label2 and scaled_similarity.item() > 0.5:\n","        correct_pred += 1\n","    elif label1 != label2 and scaled_similarity.item() < 0.5:\n","        correct_pred += 1\n","\n","    if label1 == label2:\n","      target_vector = [1]\n","    else :\n","      target_vector = [0]\n","\n","    target_tensor = torch.tensor(target_vector).float()\n","    target_tensor = target_tensor.to(DEVICE)\n","    optimizer.zero_grad()\n","    cost = loss(scaled_similarity, target_tensor)\n","    cost.backward()\n","    optimizer.step()\n","\n","    if not i % 40:\n","      print (f'Epoch: {epoch:03d}/{EPOCH:03d} | '\n","            f'Batch {i:03d}/{len(train_loader):03d} |'\n","             f' Cost: {cost:.4f}')\n","\n","    #연산량 감소를 위한 텐서 재활용\n","    image2 = image1.clone()\n","    label2 = label1\n","    vector2_tensor = vector1_tensor.detach().clone()\n","\n","elapsed = (time.time() - start_time)/60\n","print(f'Total Training Time: {elapsed:.2f} min')"],"metadata":{"id":"rBiV7BHk-4MH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 코드의 구조\n","# 1. 모델 및 환경 설정\n","# 모델을 GPU 또는 CPU로 이동하고, 필요한 변수들을 초기화합니다.\n","\n","# 2.훈련 루프 실행: 지정된 에포크 수만큼 모델을 학습시킵니다.\n","# 각 에포크마다 모델을 훈련 모드로 설정하고, 정확도 계산을 위한 변수를 초기화합니다.\n","\n","# 3. 데이터 로딩 및 전처리: train_loader를 통해 배치 단위로 데이터를 불러옵니다.\n","# 이미지를 DEVICE로 이동시키고, 라벨을 가져옵니다.\n","# 이미지를 모델에 입력하여 특징 벡터를 얻습니다.\n","\n","# 4. 유사도 계산 및 손실 함수 적용\n","# 현재 배치의 특징 벡터와 이전 배치의 특징 벡터 간의 코사인 유사도를 계산합니다.\n","# 유사도를 시그모이드 함수를 통해 [0, 1] 범위로 변환합니다.\n","# 예측된 유사도와 실제 타깃 값 간의 손실을 계산합니다.\n","\n","# 5. 역전파 및 파라미터 업데이트\n","# 옵티마이저의 그라디언트를 초기화하고, 역전파를 통해 그라디언트를 계산한 후, 파라미터를 업데이트합니다.\n","\n","# 6. 정확도 계산 및 출력\n","# 예측 결과를 기반으로 정확도를 계산합니다.\n","# 일정 간격으로 진행 상황과 손실 값을 출력합니다.\n","\n","# 7. 이전 배치 정보 업데이트\n","# 다음 배치에서 사용할 이전 배치의 정보(이미지, 라벨, 특징 벡터)를 업데이트합니다.\n","\n","# 8. 훈련 시간 측정\n","# 전체 훈련이 완료된 후, 총 훈련 시간을 계산하고 출력합니다."],"metadata":{"id":"tZ105RTImbUN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 코드에서 개선 했으면 하는 부분"],"metadata":{"id":"nc36j4O3qXZX"}},{"cell_type":"code","source":["# 데이터 분할 로직의 개선\n","from sklearn.model_selection import train_test_split\n","train_image, test_image, train_label, test_label = train_test_split(\n","    IMAGE, LABEL, test_size=0.2, stratify=LABEL, random_state=42)\n","# 현재 데이터 분할 방식은 인덱스 중복과 범위 오류의 위험이 있기에 데이터를 클래스별로 그룹화하고, train_test_split 함수를 사용하여 분할하는 것이 좋음"],"metadata":{"id":"xzsqk2gfqZR0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> 이전 코드에서 정의된 scheduler가 사용되지 않고 있다. 에포크가 끝날 때마다 검증 손실이나 정확도를 기반으로 학습률을 조정할 수 있을 것 같다.\n"],"metadata":{"id":"hFPTMB_qr5eo"}}]}
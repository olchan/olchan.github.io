## **ì£¼ìš” ê°œë… ì •ë¦¬**
#### **KNN regresion**
- ì´ì›ƒí•œ  sampleì˜ target ê°’ë“¤ì˜ í‰ê· 

#### **1ì°¨ì› ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ dataë¥¼ 2ì°¨ì›ìœ¼ë¡œ ë°”ê¾¸ê¸°**
- train_input = train_input.reshape(-1, 1)
- (n, ) : 1ì°¨ì› ë°°ì—´ => (n,1) : 2ì°¨ì› ë°°ì—´
- "-1"ì„ ì‚¬ìš©í•˜ë©´ ë°°ì—´ì˜ ì „ì²´ ì›ì†Œ ê°œìˆ˜ë¥¼ ë§¤ë²ˆ ì™¸ìš°ì§€ ì•Šì•„ë„ ë˜ë¯€ë¡œ í¸ë¦¬

### **ê²°ì • ê³„ìˆ˜ R^2**
- ë¶„ë¥˜ì˜ ê²½ìš° : test sampleì„ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•œ ê°œìˆ˜ì˜ ë¹„ìœ¨ : ì •í™•ë„
- íšŒê·€ì˜ ê²½ìš° : ê²°ì •ê³„ìˆ˜ coeficient of determination R^2 ë¡œ íšŒê·€ ëª¨ë¸ í‰ê°€
- 1 - (íƒ€ê¹ƒ - ì˜ˆì¸¡)^2ì˜ í•© / (íƒ€ê¹ƒ - í‰ê· )^2ì˜ í•©
- if íƒ€ê¹ƒì´ í‰ê·  ì •ë„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ìˆ˜ì¤€ì´ë¼ë©´(ê¸°ë³¸ ëª¨ë¸ ì •ë„ë¼ë©´), ì¦‰ ë¶„ìì™€ ë¶„ëª¨ê°€ ë¹„ìŠ·í•´ì§€ë©´ R^2ëŠ” 0ì— ê°€ê¹Œì›Œì§€ê³ , ì˜ˆì¸¡ì´ íƒ€ê¹ƒì— ì•„ì£¼ ê°€ê¹Œì›Œì§€ë©´ ë¶„ìê°€ 0ì— ê°€ê¹Œì›Œì§€ê¸°ì—, 1ì— ê°€ê¹Œìš´ ê²°ì • ê³„ìˆ˜ ê°’ì„ ê°€ì§€ê²Œ ëœë‹¤.

-> ì ˆëŒ€ì ì¸ í‰ê°€ê°’

-> ì •ëŸ‰ì ì¸ í‰ê°€ê°’(ì˜ˆì¸¡ì´ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ê°€!) : ì ˆëŒ“ê°’ ì˜¤ì°¨

#### ê³¼ëŒ€ì í•© / ê³¼ì†Œì í•©
- í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì ìˆ˜ ì°¨ì´ê°€ í¬ë©´ ì¢‹ì§€ ì•Šë‹¤.
- ì¼ë°˜ì ìœ¼ë¡œ í›ˆë ¨ ì„¸íŠ¸ì˜ ì ìˆ˜ê°€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë³´ë‹¤ ì¡°ê¸ˆ ë” ë†’ë‹¤.
- í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ê³¼ëŒ€ ì í•© (over fitting)
- í…ŒìŠ¤íŠ¸ ì ìˆ˜ê°€ ë„ˆë¬´ ë†’ê±°ë‚˜ ë‘ ì ìˆ˜ê°€ ëª¨ë‘ ë‚®ìœ¼ë©´ ê³¼ì†Œ ì í•© (under fitting)

> ì‚¬ì´í‚· ëŸ°ì— ì‚¬ìš©í•˜ëŠ” í›ˆë ¨ ì„¸íŠ¸ëŠ” 2ì°¨ì› ë°°ì—´ì´ì–´ì•¼ í•œë‹¤.
- train_input = train_input.reshape(-1, 1)




```python
from sklearn.neighbors import KNeighborsRegressor
knr = KNeighborsRegressor()

# KNN íšŒê·€ ëª¨ë¸ í›ˆë ¨
knr.fit(train_input, train_target)
```


```python
knr.score(test_input, test_target)

# ë¶„ë¥˜ì˜ ê²½ìš° : ì •í™•ë„ (sampleì„ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•œ ê°œìˆ˜ì˜ ë¹„ìœ¨)
# íšŒê·€ì˜ ê²½ìš° : ê²°ì •ê³„ìˆ˜ coefficient of determination
```




    0.992809406101064

![image](https://github.com/user-attachments/assets/14fb8e12-2125-41a0-b084-dc2d10f8f350)

- SST : ê´€ì¸¡ê°’ì—ì„œ ê´€ì¸¡ê°’ì˜ í‰ê· ì„ ëº¸ ê²°ê³¼ì˜ ì´í•© => dataì˜ ë³€ë™ì„±ì„ ì˜ë¯¸
- SSE : ì¶”ì²­ ê°’ì—ì„œ ê´€ì¸¡ê°’ì˜ í‰ê· ì„ ëº€ ê²°ê³¼ì˜ ì´í•©
- SSR : ê´€ì¸¡ê°’ì—ì„œ ì¶”ì •ê°’ì„ ëº¸ ê°’ => ì”ì°¨ì˜ ì´í•© => íšŒê·€ ëª¨ë¸ì´ ì„¤ëª…í•˜ì§€ ëª»í•œ ë³€ë™ì„±
- SST = SSR + SSE
- SSEê°€ ì»¤ì§„ë‹¤ëŠ” ê²ƒì€ SSRì´ ì‘ì•„ì§„ë‹¤ëŠ” ê²ƒì´ê³ , SSEê°€ ì‘ì•„ì§€ë©´ ì„¤ëª… ë¶ˆê°€ëŠ¥í•œ ë³€ë™ì´ ì‘ì•„ì§€ëŠ” ê±°ë‹ˆê¹Œ,ìš°ë¦¬ê°€ ì¶”ì •í•œ ëª¨í˜•ì„ ë°”íƒ•ìœ¼ë¡œ ë°˜ì‘ë³€ìˆ˜ Yë¥¼ ë³´ë‹¤ ì˜ ì˜ˆì¸¡í•  ìˆ˜ ìˆê²Œ ëœë‹¤ëŠ” ê²ƒ
- ê²°ì •ê³„ìˆ˜ : íšŒê·€ ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì²™ë„

> - ê²°ì • ê³„ìˆ˜ $ğ‘…^2$ëŠ” ë…ë¦½ ë³€ìˆ˜ì˜ ê°œìˆ˜ê°€ ëŠ˜ì–´ë‚˜ë©´ ì¼ë°˜ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.
- ì´ëŠ” ëª¨ë¸ì— ìƒˆë¡œìš´ ë…ë¦½ ë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ë©´ ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ë” ì˜ ë§ì¶œ ìˆ˜ ìˆëŠ” ë” ë§ì€ ììœ ë„ë¥¼ ê°€ì§€ê²Œ ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
- í•˜ì§€ë§Œ ì´ëŸ¬í•œ ì¦ê°€ê°€ ëª¨ë¸ì˜ ì„¤ëª…ë ¥(ì¦‰, ì¼ë°˜í™” ì„±ëŠ¥)ì´ ì‹¤ì œë¡œ ë†’ì•„ì§€ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.

![image](https://github.com/user-attachments/assets/a5aa6602-9997-471a-bdaf-895a4783a86f)


```python
print(knr.score(train_input, train_target)) # -> ê³¼ì†Œ ì í•©
```

    0.9698823289099254
    

- ê³¼ì†Œ ì í•©ì„ í•´ê²° -> ëª¨ë¸ì„ ë” ë³µì¡í•˜ê²Œ!
- knn ì•Œê³ ë¦¬ì¦˜ì—ì„œëŠ” kë¥¼ ì¤„ì¸ë‹¤.
- ì´ì›ƒì˜ ê°œìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ ë°ì´í„°ì˜ ì „ë°˜ì ì¸ íŒ¨í„´ì„ í•™ìŠµí•˜ê³ , ì´ì›ƒì˜ ê°œìˆ˜ë¥¼ ì¤„ì´ë©´ ë°ì´í„°ì˜ ì§€ì—½ì ì¸ íŒ¨í„´ì„ í•™ìŠµ


```python
knr.n_neighbors = 3
knr.fit(train_input, train_target)
print(knr.score(train_input, train_target))
```

    0.9804899950518966
    

## **ì£¼ìš” ê°œë… ì •ë¦¬**
- KNN ì•Œê³ ë¦¬ì¦˜ì˜ í•œê³„
  - ì•„ë¬´ë¦¬ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆëŠ” dataë¼ë„ ë¬´ì¡°ê±´ ê°€ì¥ ê°€ê¹Œìš´ ìƒ˜í”Œì˜ íƒ€ê¹ƒì„ í‰ê· í•˜ì—¬ ì˜ˆì¸¡í•˜ê¸°ì—,í›ˆë ¨ data set ë²”ìœ„ ë°–ì˜ dataì— ëŒ€í•´ì„œëŠ” ì…ë ¥ê°’ì— ìƒê´€ì—†ì´ ê°™ì€ ê°’ì˜ ì˜ˆì¸¡ê°’ì„ ë°˜í™˜í•˜ì—¬ ì˜ˆì¸¡ì´ ë¶ˆê°€í•˜ë‹¤.

### ì„ í˜• íšŒê·€ : dataë¥¼ ì„¤ëª…í•˜ëŠ” ìµœì ì˜ ì§ì„  ì°¾ê¸°


```python
# LinearRegression í´ë˜ìŠ¤ê°€ ì°¾ì€ aì™€ bëŠ” lrê°ì²´ì˜ coef_ì™€ intercept_ ì†ì„±ì— ì €ì¥ë˜ì–´ ìˆë‹¤.
print(lr.coef_, lr.intercept_)
```
- in ë¨¸ì‹ ëŸ¬ë‹
- **ê¸°ìš¸ê¸°** : coefficient ê³„ìˆ˜ or weight ê°€ì¤‘ì¹˜ ë¼ê³  ë¶€ë¦„
- coef_ì™€ intercept_ë¥¼ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì´ ì°¾ì€ ê°’ì´ë¼ëŠ” ì˜ë¯¸ë¡œ model parameterë¼ê³  ë¶€ë¦„ => **ëª¨ë¸ ê¸°ë°˜ í•™ìŠµ**
- KNN ì•Œê³ ë¦¬ì¦˜ : ëª¨ë¸ íŒŒë¼ë¯¸í„°ê°€ ì—†ê³ , í›ˆë ¨ ì„¸íŠ¸ë¥¼ ì €ì¥í•˜ëŠ” ê²ƒì´ í›ˆë ¨ì˜ ì „ë¶€ì˜€ìŒ => **ì‚¬ë¡€ ê¸°ë°˜ í•™ìŠµ**



```python
# ê¸°ë³¸ì ì¸ ì§ì„  ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
plt.plot(x,y)
# ì…ë ¥ê°’ì´ í•˜ë‚˜ì¼ ê²½ìš°, y ê°’ì´ë¼ê³  ì¸ì‹
# ì„ ì„ ê·¸ë¦´ë•Œ, ë‹¤ì–‘í•œ ì„ ì˜ ì¢…ë¥˜ë¥¼ ì„ íƒí•  ìˆ˜ ìˆë‹¤. ë””í´íŠ¸ê°€ ì§ì„ ì´ê³ , ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ë§ˆì»¤ë‚˜ ì ì„ ë“±ì„ ì„ íƒ ê°€ëŠ¥
```

### ë‹¤í•­ íšŒê·€ : dataë¥¼ ì„¤ëª…í•˜ëŠ” ìµœì ì˜ ê³¡ì„  ì°¾ê¸°

- **2ì°¨ ë°©ì •ì‹ ê·¸ë˜í”„ë¥¼ ì°¾ê¸° ìœ„í•´ í›ˆë ¨ ì„¸íŠ¸ì— ì œê³±í•­ì„ ì¶”ê°€í–ˆì§€ë§Œ, íƒ€ê¹ƒê°’ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤.**
- **ëª©í‘œí•˜ëŠ” ê°’ì€ ì–´ë–¤ ê·¸ë˜í”„ë¥¼ í›ˆë ¨í•˜ë“ ì§€ ë°”ê¿€ í•„ìš”ê°€ ì—†ë‹¤.**

> - coef_ : íŠ¹ì„±ì— ëŒ€í•œ ê³„ìˆ˜
- intercept_ : ì ˆí¸ì´ í¬í•¨


#### **ì‚¬ì´í‚·ëŸ°ì˜ PolynomialFeatures í´ë˜ìŠ¤**
- ì‚¬ì´í‚·ëŸ°ì—ì„œ íŠ¹ì„±featuresì„ ë§Œë“¤ê±°ë‚˜ ì „ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ëª¨ë¸ í´ë˜ìŠ¤ : Transformer
- fit(), transform() ë©”ì„œë“œ
- transformerë¥¼ fití•˜ë©´ ë§Œë“¤ íŠ¹ì„±ì˜ ì¡°í•©ì„ ì¤€ë¹„í•¨
- transform ë©”ì„œë“œ : **ê° íŠ¹ì„±ì„ ì œê³±í•œ í•­, íŠ¹ì„±ë¼ë¦¬ ì„œë¡œ ê³±í•œ í•­, 1**
- 1: ì„ í˜• ë°©ì •ì‹ì˜ ì ˆí¸ì€ í•­ìƒ ê°’ì´ 1ì¸ íŠ¹ì„±ê³¼ ê³±í•´ì§€ëŠ” ê³„ìˆ˜ë¼ê³  ìƒê° => **ì‚¬ì´í‚·ëŸ°ì˜ ì„ í˜• ëª¨ë¸ì€ ìë™ìœ¼ë¡œ ì ˆí¸ì„ ì¶”ê°€í•´ì£¼ê¸°ì—, include_bias = False ë¡œ ì •í•´ì„œ íŠ¹ì„± ë³€í™˜**
- **PolynomialFeatures í´ë˜ìŠ¤ì˜ degree ë³€ìˆ˜ ì‚¬ìš©** => í•„ìš”í•œ ê³ ì°¨í•­ì˜ ìµœëŒ€ ì°¨ìˆ˜ë¥¼ ì§€ì • ê°€ëŠ¥
- But, íŠ¹ì„±ì˜ ê°œìˆ˜ë¥¼ í¬ê²Œ ëŠ˜ë¦¬ë©´ ì„ í˜• ëª¨ë¸ì€ í›ˆë ¨ setì— ëŒ€í•´ì„œë§Œ ê±°ì˜ ì™„ë²½í•˜ê²Œ í•™ìŠµ ê°€ëŠ¥ => ê³¼ëŒ€ ì í•©

### **ê·œì œ regularization**
- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ í›ˆë ¨ ì„¸íŠ¸ë¥¼ ë„ˆë¬´ ê³¼ë„í•˜ê²Œ í•™ìŠµí•˜ì§€ ëª»í•˜ë„ë¡ í›¼ë°©í•˜ëŠ” ê²ƒ
- ëª¨ë¸ì´ í›ˆë ¨ setì— ê³¼ëŒ€ì í•©ë˜ì§€ ì•Šë„ë¡ ë§Œë“œëŠ” ê²ƒ
- ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ ê²½ìš° íŠ¹ì„±ì— ê³±í•´ì§€ëŠ” ê³„ìˆ˜(ê¸°ìš¸ê¸°)ì˜ í¬ê¸°ë¥¼ ì‘ê²Œ ë§Œë“œëŠ” ì¼

#### StandardScaler() í´ë˜ìŠ¤ : í‘œì¤€í™”ë¥¼ í•˜ëŠ” ì‚¬ì´í‚·ëŸ° í´ë˜ìŠ¤

## **ë¦¿ì§€ Ridge ë¼ì˜ Lasso**
- ë¦¿ì§€ : ê³„ìˆ˜ë¥¼ ì œê³±í•œ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ê·œì œë¥¼ ì ìš©
- ë¼ì˜ : ê³„ìˆ˜ì˜ ì ˆëŒ“ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ê·œì œë¥¼ ì ìš©

- ì¼ë°˜ì ìœ¼ë¡œ ë¼ì˜ë¥¼ ì„ í˜¸
- ë‘ ì•Œê³ ë¦¬ì¦˜ ëª¨ë‘ ê³„ìˆ˜ì˜ í¬ê¸°ë¥¼ ì¤„ì´ì§€ë§Œ ë¼ì˜ëŠ” ì•„ì˜ˆ 0ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ë„ ìˆìŒ => **ìœ ìš©í•œ íŠ¹ì„±ì„ ê³¨ë¼ë‚´ëŠ” ìš©ë„ë¡œë„ ì‚¬ìš© ê°€ëŠ¥**


- ë§ì€ íŠ¹ì„±ì„ ì‚¬ìš©í–ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  í›ˆë ¨ ì„¸íŠ¸ì— ë„ˆë¬´ ê³¼ëŒ€ì í•©ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ëƒ„
- ë¦¿ì§€ì™€ ë¼ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•  ë•Œ ê·œì œì˜ ì–‘ì„ ì„ì˜ë¡œ ì¡°ì ˆ ê°€ëŠ¥
- ëª¨ë¸ ê°ì²´ë¥¼ ë§Œë“¤ ë•Œ alpha ë§¤ê°œë³€ìˆ˜ë¡œ ê·œì œì˜ ê°•ë„ë¥¼ ì¡°ì ˆ
- alphaê°’ì´ í¬ë©´ ê·œì œ ê°•ë„ê°€ ì„¸ì§€ë¯€ë¡œ ê³„ìˆ˜ ê°’ì„ ë” ì¤„ì´ê³  ì¡°ê¸ˆ ë” ê³¼ì†Œì í•©ë˜ë„ë¡ ìœ ë„
- alpha ê°’ì´ ì‘ìœ¼ë©´ ê³„ìˆ˜ë¥¼ ì¤„ì´ëŠ” ì—­í• ì´ ì¤„ì–´ë“¤ê³  ì„ í˜• íšŒê·€ ëª¨ë¸ê³¼ ìœ ì‚¬í•´ì§€ë¯€ë¡œ ê³¼ëŒ€ì í•© ê°€ëŠ¥ì„±ì´ ì¦ê°€

#### alpha ê°’ :  ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” parameter(ë³€ìˆ˜)ê°€ ì•„ë‹Œ ì‚¬ëŒì´ ì§ì ‘ ì…ë ¥í•´ì•¼ í•˜ëŠ” íŒŒë¼ë¯¸í„° => hyperparameter

> **ì ì ˆí•œ alpha ê°’ì€ R^2 ê·¸ë˜í”„ë¥¼ í†µí•´ ê²°ì • ê°€ëŠ¥**
- í›ˆë ¨ setì™€ í…ŒìŠ¤íŠ¸ setì˜ ì ìˆ˜ê°€ ê°€ì¥ ê°€ê¹Œìš´ ì§€ì ì´ ìµœì ì˜ alpha ê°’ì´ ë¨

![image](https://github.com/user-attachments/assets/466f6828-5f97-44dc-a368-f006dfb9c6f5)

![image](https://github.com/user-attachments/assets/8aa1fbec-62a5-4600-9486-6c36ade17d31)

```python
point = np.arange(15,50)

plt.scatter(train_input, train_target)

plt.plot(point, 1.01*point**2 - 21.6*point + 116.05)

plt.scatter(50,1574, marker = '^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

![output_9_0](https://github.com/user-attachments/assets/38c81a05-10c6-4304-97c4-cb0835335a0e)


> 2ì°¨ ë°©ì •ì‹ì„ í¬í•¨í•œ ë‹¤í•­ íšŒê·€(polynomial regression)ë„ ì„ í˜• íšŒê·€
-  íšŒê·€ ë¶„ì„ì—ì„œ "ì„ í˜•"ì´ë¼ëŠ” ìš©ì–´ê°€ ëª¨ë¸ì˜ í˜•íƒœê°€ ì•„ë‹Œ, íŒŒë¼ë¯¸í„°ì— ëŒ€í•´ ì„ í˜•ì ì„ì„ ì˜ë¯¸í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì¦‰, ì„ í˜• íšŒê·€ëŠ” ì¢…ì† ë³€ìˆ˜ ğ‘¦ê°€ ë…ë¦½ ë³€ìˆ˜ xì˜ í•¨ìˆ˜ë¡œ í‘œí˜„ë  ë•Œ, ê·¸ í•¨ìˆ˜ì˜ ê³„ìˆ˜(íŒŒë¼ë¯¸í„°)ê°€ ì„ í˜•ì ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ê²½ìš°ë¥¼ ë§í•©ë‹ˆë‹¤.
- ë¹„ì„ í˜• íšŒê·€ì˜ ê²½ìš° : ì¢…ì† ë³€ìˆ˜ yê°€ ë…ë¦½ ë³€ìˆ˜ xì˜ ë¹„ì„ í˜• í•¨ìˆ˜ë¡œ í‘œí˜„ë˜ëŠ” ê²½ìš°

## **ì£¼ìš” ê°œë… ì •ë¦¬**

#### ë‹¤ì¤‘ íšŒê·€ : ì—¬ëŸ¬ ê°œì˜ íŠ¹ì„±ì„ ì‚¬ìš©í•œ ì„ í˜• íšŒê·€
- íŠ¹ì„±ì´ 1ê°œë©´ ì„ ì„ í•™ìŠµ
- íŠ¹ì„±ì´ 2ê°œë©´ ë©´ì„ í•™ìŠµ
- íŠ¹ì„±ì´ 3ê°œ ì´ìƒì´ë©´ ê·¸ë¦´ ìˆ˜ ì—†ëŠ” ê³µê°„ì—ì„œ í‘œí˜„ -> íŠ¹ì„±ì´ ë§ì€ ê³ ì°¨ì›ì—ì„œëŠ” ì„ í˜• íšŒê·€ê°€ ë§¤ìš° ë³µì¡í•œ ëª¨ë¸ì„ í‘œí˜„ ê°€ëŠ¥

#### **íŠ¹ì„± ê³µí•™ feature engineering** : ê¸°ì¡´ì˜ íŠ¹ì„±ì„ ì‚¬ìš©í•´ ìƒˆë¡œìš´ íŠ¹ì„±ì„ ë½‘ì•„ë‚´ëŠ” ì‘ì—…



```python
lasso = Lasso(alpha = 10)
lasso.fit(train_scaled, train_target)
print(lasso.score(train_scaled, train_target))
print(lasso.score(test_scaled, test_target))
```

    0.9888067471131867
    0.9824470598706695
    


```python
print(np.sum(lasso.coef_ == 0))
# ë¼ì˜ ëª¨ë¸ì€ 55ê°œì˜ featureë“¤ ì¤‘ 15ê°œì˜ íŠ¹ì„±ë§Œì„ ì‚¬ìš©
```

    40
    

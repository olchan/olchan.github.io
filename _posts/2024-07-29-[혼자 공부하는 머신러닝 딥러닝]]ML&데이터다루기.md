## **이진 분류** : 도미와 빙어 구분하기 문제

- 보통의 프로그램 : 누군가가 정한 기준대로 일을 수행
- 머신러닝 : 누구도 알려주지 않은 기준을 찾아서 일을 수행

> **이진분류**
- 여러 개의 종류 중 하나를 구별 => 분류 classification
- 2개의 class 중 1개를 고르는 문제 : 이진 분류


```python
plt.scatter(bream_length, bream_weight, label='bream')
plt.scatter(smelt_length, smelt_weight, label='smelt')
plt.xlabel('length')
plt.ylabel('weight')
plt.legend()
plt.show()
```
    

![output_1_0](https://github.com/user-attachments/assets/f2ab74cc-7eb9-4441-8b4f-0c86ed0c8d42)

```python
from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier()
kn.fit(fish_data, fish_target)
```

> K-최근접 이웃 알고리즘
- 가장 가까운 직선 거리에 존재하는 k개의 데이터들의 비율을 보고 다수를 차지하는 것을 정답으로 결정
- k를 너무 크게 하면 전체 data의 분포 중 큰 값으로 예측이 되기에, 조심해야 한다.



## **데이터 다루기**

- sampling 편향 : 훈련 세트와 테스트 세트에 샘플이 골고루 섞여 있지 않으면, 샘플링이 한 쪽으로 치우쳤다는 의미로 샘플링 편향이라고 한다.
- 데이터를 순서에 변형 없이 split해서 test, train set으로 학습할 경우 발생하기 쉬운 오류


**numpy** : 배열의 차원을 구분하기 쉽도록 행과 열을 가지런히 출력해준다.
- np.shape : (샘플수, 특성 수) 반환
- input_arr = np.array(fish_data) => 2차원의 배열로 바꿔줌
---
- 배열을 섞은 후에 나누는 방식 대신, 무작위로 샘플을 고르는 방식으로 train test set split
- input_arr와 target_arr에서 같은 위치는 함께 선택되어야 한다.
-
```python
np.random.seed(42) # random seed 고정
index = np.arange(49) # 0부터 1씩 증가하는 배열 생성
np.random.shuffle(index)
# 이후 train / test set 분리
train_input = input_arr[index[:35]]
train_target = target_arr[index[:35]]
```
### 배열 Indexing
- 1개의 인덱스가 아닌 여려 개의 인덱스로 한 번에 여러 개의 원소를 선택할 수 있습니다. 예를 들면 다음처럼 input_arr에서 두 번째와 네 번째 샘플을 선택하여 출력할 수 있습니다.

 ex) print(input_arr[[1,3]])

---
- fit 메서드를 실행할 때마다 KNeighborsClassigier 클래스의 객체는 이전에 학습한 모든 것을 잃어버린다. 이전 모델을 그대로 두고 싶다면 KNN 클래스 객체를 새로 만들어야 한다.



```python
# train, test data는 편향이 없이, 전체 data에 대한 대표성을 가질 수 있게 골고루 분포되어 있어야 한다.
import matplotlib.pyplot as plt
plt.scatter(train_input[:,0], train_input[:,1])
plt.scatter(test_input[:,0], test_input[:,1])
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

![output_5_0](https://github.com/user-attachments/assets/c980f21d-b007-4191-b0ce-3e7f440f5575)

## 데이터 전처리
- #### **numpy의 column_stack 함수** : 전달받은 리스트를 일렬로 세운 다음 차례대로 나란히 연결
- 연결할 리스트는 **파이썬 tuple로 전달**
- numpy로 된 배열을 출력하면 리스트처럼 한 줄로 길게 출력되지 않고, 행과 열을 맞추러 가지런히 정리된 모습으로 보여준다.

```python
print(np.ones(5))
# >> 11111
```
- np.concatenate() : 두 배열을 첫번째 차원을 따라 연결 <-> **column_stack()**

```python
# stratify = 타깃 data 명 => 클래스 비율에 맞게 data 분할, 훈련 data가 작거나 특정 클래스의 샘플 개수가 적을 때 특히 유용
train_input, test_input, train_target, test_target = train_test_split(fish_data, fish_target, stratify = fish_target, random_state = 42)
```
### **스케일이 다른 특성 처리**
- 분류 모델과 다르게, 거리 기반의 모델들은 특성의 스케일이 다르면 잘 작동하지 않는다.

#### Scale
- 두 특성의 값이 놓인 범위가 매우 다르다. 이를 두 특성의 스케일이 다르다고 표현.

- 특성값을 일정한 기준으로 맞춰 주는 데이터 전처리 data preprocessing 이 필요!

#### Z score
- 표준 점수 : 각각의 data가 원점에서 몇 표준편차만큼 떨어져 있는지를 나타내는 값

#### **Broad Casting**
- numpy의 array 안의 모든 행에 동일한 계산을 적용해준다.

- 주의할 점!
  - 훈련 세트를 변환한 방식 그대로 테스트 세트를 변환해주어야 한다! => 훈련 set의 평균과 표준편차로 test set을 표준화한다.


```python
import numpy as np
arr1  = np.array([0,1,2,3,4,5,6])
arr1 [4:6] = -1
arr1
# np array는 가능
```




    array([ 0,  1,  2,  3, -1, -1,  6])




```python
list1  = [0,1,2,3,4,5,6]
list1 [4:6] = -1
list1
# list는 불가능
```


    ---------------------------------------------------------------------------

    TypeError                                 Traceback (most recent call last)

    <ipython-input-23-28ae4cf46d6c> in <cell line: 2>()
          1 list1  = [0,1,2,3,4,5,6]
    ----> 2 list1 [4:6] = -1
          3 list1
          4 # list는 불가능
    

    TypeError: can only assign an iterable



```python
list2  = [0,1,2,3,4,5,6]
list2 [4:6] = -1, -1
list2
# Unpacking으로만 가능
```




    [0, 1, 2, 3, -1, -1, 6]

